{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load python modules : Plot, image , numerical python \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Set a useful font library\n",
    "font1 = {'size'   : 20, 'family':'STIXGeneral'}\n",
    "#Colors for plotting \n",
    "colors = ['teal', 'yellowgreen', 'gold']\n",
    "#line width for plottting\n",
    "lw = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will start with a regression problem using sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the power spectrum data. Columns: k , P(k) w BAO feature , P(k) w/o BAO feature\n",
    "dat1 = np.loadtxt(\"data/PT_z0.dat\")\n",
    "length = len(dat1);\n",
    "\n",
    "#set training data proportion \n",
    "m = int(length*0.5)\n",
    "\n",
    "k_pt = dat1[:,0]\n",
    "baotab = dat1[:,1]/dat1[:,2]\n",
    "bao =  interp1d(k_pt, baotab, kind='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot BAO signal\n",
    "\n",
    "# Set figure size \n",
    "plt.figure(figsize=(5,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "#Plot 1st column against 2nd column \n",
    "plt.plot(k_pt, bao(k_pt), label='$z=0$', alpha=0.6 , linestyle='solid', marker='x', color='red')\n",
    "\n",
    "#Plot the legend\n",
    "plt.legend(loc='best',prop={'size': 16})\n",
    "\n",
    "#Set ranges\n",
    "plt.ylim(0.9,1.1)\n",
    "plt.xlim(0.001,0.5)\n",
    "\n",
    "#Format axes \n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.ylabel('$ P(k)/P_{NW}(k)$',**font1)\n",
    "plt.xlabel('$k [h/{\\\\rm Mpc}]$', **font1)\n",
    "plt.legend(loc='best',prop={'size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to apply linear regression to this problem....\n",
    "\n",
    "#Load sklearn regression algorithm \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Set degree of polynomial, regularisation and maximum k to plot\n",
    "mylam = 0\n",
    "degree = 1\n",
    "kmax = 0.2\n",
    "\n",
    "# Training set \n",
    "train_k = dat1[:m,0]\n",
    "train_bao = bao(train_k)\n",
    "\n",
    "# Test set \n",
    "test_k = dat1[:,0]\n",
    "test_bao = bao(test_k)\n",
    "\n",
    "\n",
    "# create matrix versions of these arrays\n",
    "X = train_k[:, np.newaxis]\n",
    "X_plot = test_k[:, np.newaxis]\n",
    "\n",
    "\n",
    "# The ridge model fits with a cost function : \n",
    "#  J(w) = ||y - Xw||^2_2 + alpha * ||w||^2_2  \n",
    "\n",
    "mycost = [(Ridge(alpha=mylam))]\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(degree), estimator)\n",
    "model.fit(X, train_bao)\n",
    "y_plot = model.predict(X_plot)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "ax = plt.subplot(1,2,1)\n",
    "\n",
    "plt.plot(test_k, test_bao, color='cornflowerblue', linewidth=lw,label=\"Truth\")\n",
    "\n",
    "plt.scatter(train_k, train_bao, color='navy', s=30, marker='o', label=\"training points\")\n",
    "\n",
    "plt.plot(test_k, y_plot, color=colors[count], linewidth=lw, label=\"degree: %d\" % degree)\n",
    "\n",
    "\n",
    "plt.legend(loc='lower left')\n",
    "#Set ranges\n",
    "plt.ylim(0.9,1.1)\n",
    "plt.xlim(0.001,kmax)\n",
    "\n",
    "#Format axes \n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.ylabel(' BAO signal ',**font1)\n",
    "plt.xlabel('$k [h/{\\\\rm Mpc}]$', **font1)\n",
    "plt.legend(loc='best',prop={'size': 16})\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "if (degree>20 and kmax<0.26): \n",
    "    img = mpimg.imread('data/bor2.jpg')\n",
    "else : \n",
    "    img = mpimg.imread('data/bor1.jpg')\n",
    "    \n",
    "plt.imshow(img)\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try a classification example: power spectra into f(R) and GR  classes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First try to identify some useful features  - taking each k-bin will certainly not be optimal! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some examples to investigate \n",
    "\n",
    "exampleno = 50\n",
    "\n",
    "#Columns: k , P(k) w BAO feature , P(k) w/o BAO feature\n",
    "fr_exp = np.loadtxt('data/class/fr_mlg/'+str(exampleno)+'.txt')\n",
    "gr_exp = np.loadtxt('data/class/gr_mlg/'+str(exampleno)+'.txt')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "#Pure spectra \n",
    "plt.plot(fr_exp[:,0],fr_exp[:,1], color='r')\n",
    "plt.plot(gr_exp[:,0],gr_exp[:,1], color='b')\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.ylabel(' $P(k)$ ',**font1)\n",
    "plt.xlabel('$k [h/{\\\\rm Mpc}]$', **font1)\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "#BAO signal \n",
    "plt.plot(fr_exp[:,0],fr_exp[:,1]/fr_exp[:,2], color='r', label='f(R)')\n",
    "plt.plot(gr_exp[:,0],gr_exp[:,1]/gr_exp[:,2], color='b', label='GR')\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.ylabel(' BAO signal ',**font1)\n",
    "plt.xlabel('$k [h/{\\\\rm Mpc}]$', **font1)\n",
    "plt.legend(loc='best',prop={'size': 16})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear enhancement of power in f(R) cosmologies - we can use this to classify the spectra \n",
    "\n",
    "We will load the values very crudely - Pandas tutorial will teach us how to do this more elegantly! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a high k value array from k = 0.1 to 0.25\n",
    "dat2 = np.loadtxt('data/class/gr_mlg/1.txt')\n",
    "kvalues = fr_exp[20:50,0]\n",
    "print(kvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of examples per class \n",
    "import os\n",
    "path, dirs, files = next(os.walk(\"./data/class/fr_mlg\"))\n",
    "file_count = len(files) # We set aside 100 values for testing!  \n",
    "\n",
    "# number of files to be included in test set \n",
    "test_set = 101\n",
    "\n",
    "# Define an array to store the various values of P(k) at a low k and another at a high k\n",
    "high_fr = []\n",
    "high_gr = []\n",
    "low_fr = []\n",
    "low_gr = []\n",
    "\n",
    "\n",
    "#Maximum and minimum index to find maximum and minimum of spectrum \n",
    "maxi = 50\n",
    "mini = 20\n",
    "\n",
    "# Load the P(k) values per k \n",
    "for i in range(file_count-test_set):\n",
    "    datfr = np.loadtxt('data/class/fr_mlg/'+str(i+1)+'.txt')\n",
    "    datgr = np.loadtxt('data/class/gr_mlg/'+str(i+1)+'.txt')\n",
    "    \n",
    "    #perform rough feature normalisation \n",
    "    norm = np.mean(datgr[mini:maxi,1])\n",
    "    \n",
    "    high_fr.append(np.max(datfr[mini:maxi,1]/norm))\n",
    "    low_fr.append(np.min(datfr[mini:maxi,1]/norm))  \n",
    "    high_gr.append(np.max(datgr[mini:maxi,1]/norm))\n",
    "    low_gr.append(np.min(datgr[mini:maxi,1]/norm))\n",
    "\n",
    "    \n",
    "    \n",
    "total_low = np.concatenate((low_gr,low_fr), axis=None)\n",
    "total_high = np.concatenate((high_gr,high_fr), axis=None)\n",
    "\n",
    "\n",
    "plt.plot(low_fr,high_fr, linestyle='none',marker='x', label='f(R)')\n",
    "plt.plot(low_gr,high_gr, linestyle='none',marker='o', label='GR')\n",
    "plt.ylabel('Maximum $P(k)$ ',**font1)\n",
    "plt.xlabel('Minimum $P(k)$', **font1)\n",
    "plt.legend(loc='best',prop={'size': 16})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now fit a decision boundary to this - linear will work well\n",
    "\n",
    "# Define logistic function first \n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "xplot = np.linspace(-5,5,100)\n",
    "\n",
    "plt.plot(xplot,sigmoid(xplot))\n",
    "plt.axvline(x=0., ymin=0., ymax=10,color='k')\n",
    "plt.axhline(y=1., xmin=-5, xmax=5,color='k',linestyle='dotted')\n",
    "plt.axhline(y=0., xmin=-5, xmax=5,color='k',linestyle='dotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our cost function \n",
    "# x is an 3 x m matrix - (1, x1, x2) per example , x1 and x2 are our features (max and min P(k))\n",
    "# y is an m x 1 matrix - 0 or 1 per example \n",
    "# w is an 3 x 1 matrix - (bias, w1, w2) \n",
    "# w.T is w transpose \n",
    "\n",
    "def mycost(w,x,y,m):\n",
    "    myunity = np.ones(m)\n",
    "    sigmoidmat = sigmoid(np.matmul(x.T,w))    \n",
    "    term1 = np.matmul(y.T,np.log(sigmoidmat))\n",
    "    \n",
    "    term2 = np.matmul((myunity-y).T,np.log(myunity-sigmoidmat))\n",
    "    \n",
    "    return -1/m * (term1 + term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix of features \n",
    "bias = np.ones((file_count-test_set)*2)\n",
    "training_x = np.concatenate(([bias],[total_low],[total_high]))\n",
    "# Create vector of 'right' answers \n",
    "training_y = np.concatenate((np.zeros((file_count-test_set)),np.ones((file_count-test_set))))\n",
    "\n",
    "# Test cost function for initial guess \n",
    "winit = np.array([10,-10,1])\n",
    "mycost(winit, training_x, training_y , (file_count-test_set)*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scipy module to optimise the function using a gradient descent algorithm\n",
    "import scipy.optimize as optimize\n",
    "\n",
    "xopt = optimize.fmin(mycost, winit , args=(training_x, training_y , (file_count-test_set)*2), xtol=1e-5, disp=True)\n",
    "\n",
    "print(xopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot decision boundary\n",
    "def decbound(w,x):\n",
    "    return -(w[0] + w[1]*x)/w[2]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "ax = plt.subplot(1,2,1)\n",
    "plt.plot(total_low, decbound(xopt,total_low))\n",
    "plt.plot(low_fr,high_fr, linestyle='none',marker='x', label='f(R)')\n",
    "plt.plot(low_gr,high_gr, linestyle='none',marker='o', label='GR')\n",
    "plt.ylabel('Maximum $P(k)$ ',**font1)\n",
    "plt.xlabel('Minimum $P(k)$', **font1)\n",
    "plt.legend(loc='best',prop={'size': 16})\n",
    "\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "img = mpimg.imread('data/bor3.jpg')\n",
    "plt.imshow(img)\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check how accurate our fit is \n",
    "\n",
    "# Define a prediction based on our fit \n",
    "def predictor(x1,x2):\n",
    "    if(sigmoid(xopt[0] + xopt[1]*x1 + xopt[2]*x2)>=0.5):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Create test data from the  unused examples\n",
    "high_frt = []\n",
    "high_grt = []\n",
    "low_frt = []\n",
    "low_grt = []\n",
    "\n",
    "for i in range(file_count-test_set,file_count-1):\n",
    "    \n",
    "    datfr = np.loadtxt('data/class/fr_mlg/'+str(i+1)+'.txt')\n",
    "    datgr = np.loadtxt('data/class/gr_mlg/'+str(i+1)+'.txt')\n",
    "    \n",
    "    #perform rough feature normalisation \n",
    "    norm = np.mean(datgr[mini:maxi,1])\n",
    "    \n",
    "    high_frt.append(np.max(datfr[mini:maxi,1]/norm))\n",
    "    low_frt.append(np.min(datfr[mini:maxi,1]/norm))  \n",
    "    high_grt.append(np.max(datgr[mini:maxi,1]/norm))\n",
    "    low_grt.append(np.min(datgr[mini:maxi,1]/norm))\n",
    "\n",
    "    \n",
    "total_low_test = np.concatenate((low_grt,low_frt), axis=None)\n",
    "total_high_test = np.concatenate((high_grt,high_frt), axis=None)\n",
    "\n",
    "# Create matrix of features \n",
    "test_x = np.concatenate(([total_low_test],[total_high_test]))\n",
    "# Create vector of 'right' answers \n",
    "test_y = np.concatenate((np.zeros((test_set-1)),np.ones((test_set-1))))\n",
    "\n",
    "# Calculate the accuracy \n",
    "myacc = 0\n",
    "\n",
    "for i in range(test_set*2-2):\n",
    "    if(predictor(test_x[0][i],test_x[1][i])==test_y[i]):\n",
    "        myacc +=1 \n",
    "        \n",
    "print(myacc/(test_set*2-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_low, decbound(xopt,total_low))\n",
    "plt.plot(low_frt,high_frt, linestyle='none',marker='x', label='f(R)')\n",
    "plt.plot(low_grt,high_grt, linestyle='none',marker='o', label='GR')\n",
    "plt.ylabel('Maximum $P(k)$ ',**font1)\n",
    "plt.xlabel('Minimum $P(k)$', **font1)\n",
    "plt.legend(loc='best',prop={'size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
